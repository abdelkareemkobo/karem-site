<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>kareem&#39;s Blog</title>
<link>https://kareemai.com/til/</link>
<atom:link href="https://kareemai.com/til/index.xml" rel="self" type="application/rss+xml"/>
<description>Kareem Elkhateb personal site, a blog about machine learning, deep learning, Web developement with Astrojs,fastapi aslo arabic Natural Language Processing and Rust language.</description>
<image>
<url>https://user-images.githubusercontent.com/1483922/208359430-f55d7503-3a98-4875-a35c-16314c9439d0.png</url>
<title>kareem&#39;s Blog</title>
<link>https://kareemai.com/til/</link>
</image>
<generator>quarto-1.6.40</generator>
<lastBuildDate>Sat, 17 May 2025 21:00:00 GMT</lastBuildDate>
<item>
  <title>Explore the Qdrant Blog core concepts | Part 1</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/til/tils/2025-05-18-til.html</link>
  <description><![CDATA[ 




<section id="overview-of-qdrant-features-and-concepts" class="level2">
<h2 class="anchored" data-anchor-id="overview-of-qdrant-features-and-concepts">Overview of Qdrant features and Concepts</h2>
<p>I will divide the blogs into 3 types:</p>
<ol type="1">
<li><p>Startups using Qdrant: why and comparision you get read nice usecases with some numbers of comparision and how qdrant is amazing</p></li>
<li><p>Startup using Qdrant++: The same but with code snippets and System Design discussion..very useful for me as a developer</p></li>
<li><p>Qdrant releases: New features in Qdrant and how to use them.</p></li>
</ol>
<p><strong>Remember this when i will build Agentic RAG in the new job</strong></p>
<p>users tend to ask more structured, analytical questions when they know a database is involved—queries better suited to SQL than vector search. This prompted the team to pair Qdrant with a text-to-SQL system, blending unstructured and structured query capabilities for a more versatile agent.</p>
<section id="hotel-search-with-vectors" class="level3">
<h3 class="anchored" data-anchor-id="hotel-search-with-vectors">Hotel Search with Vectors</h3>
<p>Superlinked enhances search by embedding each attribute (text, numbers, categories) into specialized spaces, enabling nuanced, multi-attribute queries.</p>
<p>An LLM interprets user intent, assigning weights to preferences (e.g., price, rating), allowing flexible, business-driven ranking without system redesign.</p>
<p>Hard filters narrow results, while weighted nearest neighbor search ranks them by user preferences.</p>
<p>This unified approach supports multimodal search—combining semantic text, scaled numerical, and categorical data—preserving relationships and preference strengths.</p>
<p>Unlike traditional systems that separate or flatten data, Superlinked enables simultaneous, weighted consideration of all attributes, solving challenges like reconciling</p>
<p>results across types and capturing nuanced user intent.</p>
</section>
<section id="reciprocal-rank-rusion-rrf" class="level3">
<h3 class="anchored" data-anchor-id="reciprocal-rank-rusion-rrf">Reciprocal Rank Rusion (RRF)</h3>
<p>Qdrant’s native support for Reciprocal Rank Fusion (RRF) streamlined their retriever implementations, reducing hybrid search code by 80%. The multi-vector capabilities also enabled more sophisticated retrieval methods that better captured semantic relationships.</p>
</section>
<section id="qdrant-1.13-gpu-indexing" class="level3">
<h3 class="anchored" data-anchor-id="qdrant-1.13-gpu-indexing">Qdrant 1.13 GPU Indexing</h3>
<p>Here is summary of these new features</p>
<section id="gpu-accelerated-indexing-with-qdrant" class="level4">
<h4 class="anchored" data-anchor-id="gpu-accelerated-indexing-with-qdrant">GPU Accelerated Indexing with Qdrant</h4>
<p><strong>You can Index over all majro GPU vendors including NVIDIA,AMD and Intel that support Vulkan API to get speeds up to 10x faster than CPU-based methods</strong>*</p>
<p>As of right now this solution supports only on-premises deployments, but they will introduce support for Qdrant Cloud shortly.</p>
<p>Additional benefits:</p>
<ol type="1">
<li><p>Multi-GPU support</p></li>
<li><p>GPU indexing supports all quantization options and datatypes in Qdrant</p></li>
</ol>
</section>
<section id="strict-mode-for-opertional-control" class="level4">
<h4 class="anchored" data-anchor-id="strict-mode-for-opertional-control">Strict mode for Opertional Control</h4>
<p>Strict Mode enforces operational controls in distributed Qdrant deployments. It limits resource-intensive operations (like unindexed filtering and large batch sizes), sets boundaries on search parameters, and adds safeguards for payload sizes and timeouts. This prevents system overload, solves the “noisy neighbor” problem, and ensures reliable performance—especially in multi-tenant or serverless environments.</p>
</section>
<section id="hnsw-graph-compression" class="level4">
<h4 class="anchored" data-anchor-id="hnsw-graph-compression">HNSW Graph Compression</h4>
<p>Make search lighter on memory wihtout sacrificing speed with Delta Encoding.</p>
<p>Delta Encoding is a clever way to compress data by storing only the differences (or “deltas”) between values. It’s commonly used in search engines (for the classical inverted index) to save space and improve performance. <em>I think i have read this with Colbertv2 using similar techniques to reduce the siz </em> it’s called <strong>residual compression mechanism</strong> needs more searching</p>
<p>It’s now used for HNSW graph structure that powers Qdrant’s search.</p>
</section>
</section>
</section>
<section id="static-embedding-with-qdrant-and-model2vec" class="level2">
<h2 class="anchored" data-anchor-id="static-embedding-with-qdrant-and-model2vec">Static Embedding with Qdrant and Model2vec</h2>
<p>Static embedding from minishLab reduce the model size with 15x reduction and up to 500x speed increase while the maintain more than 85% of the performance levels. it’s like our <a href="https://kareemai.com/blog/posts/minishlab/zaraah.html">zaraah model</a> for arabic.</p>
<p>Static embedding are dense embedding so you can also use with qdrant collections. The retrieval is not going to be any faster becuase static embeddings. but the speedup is in creating the vectors from your data and encoding the queries.</p>
<p>If you want to make the retrieval faster use the following: 1. Matryoshka Embeddings 2. Quantization methods like (Scalar and Binary Quantization) ### When to use Static Embeddings ?</p>
<ol type="1">
<li><p><strong>Mobile applications</strong> - although many smartphones have powerful CPUs or even GPUs, the battery life is still a concern, and the static embeddings might be a good compromise between the quality and the power consumption. Moreover, the static embeddings can be used in the applications that require offline mode.</p></li>
<li><p><strong>Web browser extensions</strong> - running a transformer-based model in a web browser is usually not quite an option, but static embeddings might be a good choice, as they have fewer parameters and are faster to encode.</p></li>
<li><p><strong>Embedded systems</strong> - the static embeddings might be a good choice for the devices with limited computational power, such as IoT devices or microcontrollers.</p></li>
</ol>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References:</h3>
<p>There is more text in here from Qdrant not me..you can continue reading here</p>
<ol type="1">
<li><p><a href="https://qdrant.tech/blog/superlinked-multimodal-search/">Hotel Search</a></p></li>
<li><p><a href="https://qdrant.tech/blog/">Qdrant Blog</a></p></li>
<li><p><a href="https://qdrant.tech/blog/static-embeddings/">Static Embedding</a></p></li>
</ol>


</section>
</section>

 ]]></description>
  <category>blogging</category>
  <category>til</category>
  <category>qdrant</category>
  <guid>https://kareemai.com/til/tils/2025-05-18-til.html</guid>
  <pubDate>Sat, 17 May 2025 21:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/til/tils/til.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>TIL ? Tody I lernt to create TIL</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/til/tils/2025-05-17-til.html</link>
  <description><![CDATA[ 




<section id="why-til" class="level2">
<h2 class="anchored" data-anchor-id="why-til">Why TIL ?</h2>
<p>It helps you overcome the perfacationsim in writting. you don’t need to create great article in depth about things you want to share or learn about..etc, all what you want it to write a thing you were trying to learn or solve today and how you solve it</p>
<p>which will help me more focused and make the process of learning more easier and useful for me and others</p>
</section>
<section id="create-your-own-gravitey" class="level2">
<h2 class="anchored" data-anchor-id="create-your-own-gravitey">create your own gravitey</h2>
<p>sometimes you want to reach and communicate with people in the same space of problems you are solving, search engines are very bad in provide the information you want..this is related to how these engines work and other SEO stuff. but for me, i can’t reach people and help them or get benefit from them because they simple don’t know about me!!</p>
<p>TIL will decreases this spaces and daily TIl about the things i am learning which are alot will start to give me nice SEO and unique because i am talking about things i don’t know and i am interested in and there will be much people in the same boat this will increase my X account and linkedin and this is very useful in the current time.</p>
</section>
<section id="tils-level-up" class="level2">
<h2 class="anchored" data-anchor-id="tils-level-up">TILs level up</h2>
<p>I also want to think in way to extract more crafted blogs from my TILs. but just start making it habbit and will see who will it comes in the end.</p>
<p>initial thoughts: 1. weekly recap from my TILs and SEO optimization for the keywords that is increasing and i am interested in 2. ML to extract related stuff, for example i will want to take about the folloinwg topics: - Late interaciton (Pylate, Colbertv2, ColPali) - Searching - Model2vec - Visino Language models..etc collecting them and start writing about them and adding internal links for them will be very useful to improve my blog system</p>
</section>
<section id="things-i-learned-the-last-2-days" class="level2">
<h2 class="anchored" data-anchor-id="things-i-learned-the-last-2-days">Things i learned the last 2 days</h2>
<section id="the-best-way-to-increase-traffic-is-comment-with-valuble-knowledge." class="level3">
<h3 class="anchored" data-anchor-id="the-best-way-to-increase-traffic-is-comment-with-valuble-knowledge.">The best way to increase traffic is comment with valuble knowledge.</h3>
<p>I was scorlling on X and found some popular account tweets about Harvard CS197 AI Research and i had create a review year ago about it I add the link in the comment and just slept. Boom i found reply analytics links opened wihtout annoying anyone!! - 501 Impressions - 77 Engagements - 2 profile visits - 74 clicks</p>
</section>
</section>
<section id="what-is-palid-index" class="level2">
<h2 class="anchored" data-anchor-id="what-is-palid-index">What is PALID index?</h2>
<p>PLAID index is for indexing very large datasets with Later interaction models like (Colbertv2 &amp; ColPali) IT Solves the storage footprint and allow you to scale to infinity</p>
<p>They swapped the faiss from facebook what is nice thing because i have multiple bad time to install it especially the GPU version.</p>
<p>and used fastkeamns from the amazing <span class="citation" data-cites="bclaive">@bclaive</span> which i really like his work on embeddings</p>
<p>It’s replacement for Voyager-based HNSW index which was very bad for scaling Late-Interaction retrieval models</p>
</section>
<section id="prime-intellect-vs-gpuvec" class="level2">
<h2 class="anchored" data-anchor-id="prime-intellect-vs-gpuvec">Prime Intellect VS Gpuvec</h2>
<p>I was creating a website to find and compare the cloud compute instances from all cloud providers in easy and interactive way.</p>
<p>I started to work on it the last month, but stoped for other work.</p>
<p>suddenly i found this website which is called Prime intellect.</p>
<p>And i just want to say,woooooow. it’s a piece of art. The design and information on it and how fast, accurate is very embrassing for my poor gpuvec.com</p>
<p>should i continue improve my website?</p>
<p>Actually yes, we share similar goals but there is multiple chances to compete or even collaborite!! who knows!</p>
<p>They are more than just listing and compare prices, then enable you to use these GPUs from their website.</p>
<p>Also they create decentralized models and have a mutliple expirened engineers.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><a href="https://x.com/antoine_chaffin/status/1923378986219958526">Antoine tweet</a></li>
<li><a href="https://betatim.github.io/posts/til-explained/">betatim TIL</a></li>
<li><a href="https://kareemai.com/til/">other TILs</a></li>
</ol>


</section>

 ]]></description>
  <category>blogging</category>
  <category>til</category>
  <guid>https://kareemai.com/til/tils/2025-05-17-til.html</guid>
  <pubDate>Fri, 16 May 2025 21:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/til/tils/til.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
